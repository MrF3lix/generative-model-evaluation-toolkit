{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3cb250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea77fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_BASE_PATH = f'../../../../03_datasets/sentiment-analysis_stories/annotations'\n",
    "\n",
    "MODEL = {\n",
    "    'Llama-3.3-70B': f'{ANNOTATION_BASE_PATH}/25-04-24_Annotator-Training_Llama3-3.jsonl',\n",
    "    'Llama-2-7B': f'{ANNOTATION_BASE_PATH}/25-04-24_Annotator-Training_Llama2.jsonl',\n",
    "    'Mistral-7B': f'{ANNOTATION_BASE_PATH}/25-04-24_Annotator-Training_Mistral.jsonl',\n",
    "}\n",
    "\n",
    "ANNOTATION_BASE_PATH = f'../../../../03_datasets/animals/annotations'\n",
    "IMAGE_MODEL = {\n",
    "    'Stable Diffusion 3.5': f'{ANNOTATION_BASE_PATH}/25-05-05_Stable-Diffusion-3.5.jsonl',\n",
    "    'Stable Cascade': f'{ANNOTATION_BASE_PATH}/25-05-05_Stable-Cascade.jsonl',\n",
    "    'FLUX.1-dev': f'{ANNOTATION_BASE_PATH}/25-05-05_FLUX.1-dev.jsonl'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49e7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "def get_sentiment(match):\n",
    "    for sentiment in sentiments:\n",
    "        if sentiment in match:\n",
    "            return sentiment\n",
    "        \n",
    "title_match = ['match', 'no_match']\n",
    "def get_title_match(match):\n",
    "    for m in title_match:\n",
    "        if m in match:\n",
    "            return m\n",
    "        \n",
    "annotators = ['saaf', 'deri', 'vode']\n",
    "def get_annotator(match):\n",
    "    for annotator in annotators:\n",
    "        if annotator in match:\n",
    "            return annotator\n",
    "        \n",
    "animal_match = ['animal_match', 'animal_no_match']\n",
    "def get_animal_match(match):\n",
    "    for m in animal_match:\n",
    "        if m in match:\n",
    "            return m\n",
    "        \n",
    "count_match = ['count_match', 'count_no_match']\n",
    "def get_count_match(match):\n",
    "    for m in count_match:\n",
    "        if m in match:\n",
    "            return m\n",
    "\n",
    "def get_oracle_ratings_per_annotator(path):\n",
    "    df = pd.read_json(path, orient='records', lines=True)\n",
    "    df['id'] = df['meta'].apply(lambda m: m['id'])\n",
    "    df['annotator'] = df['_annotator_id'].apply(get_annotator)\n",
    "    df['oracle'] = df['accept'].apply(get_sentiment)\n",
    "    df['oracle_title_match'] = df['accept'].apply(get_title_match)\n",
    "\n",
    "    df_an1 = df.loc[df['annotator'] == 'deri'][['id', 'oracle', 'oracle_title_match']]\n",
    "    df_an2 = df.loc[df['annotator'] == 'vode'][['id', 'oracle', 'oracle_title_match']]\n",
    "\n",
    "    return df_an1, df_an2\n",
    "    \n",
    "def get_oracle_ratings_per_annotator_image(path):\n",
    "    df = pd.read_json(path, orient='records', lines=True)\n",
    "    df['id'] = df['meta'].apply(lambda m: m['id'])\n",
    "    df['annotator'] = df['_annotator_id'].apply(get_annotator)\n",
    "    df['oracle_animal'] = df['accept'].apply(get_animal_match)\n",
    "    df['oracle_count'] = df['accept'].apply(get_count_match)\n",
    "\n",
    "    df_an1 = df.loc[df['annotator'] == 'deri'][['id', 'oracle_animal', 'oracle_count']]\n",
    "    df_an2 = df.loc[df['annotator'] == 'vode'][['id', 'oracle_animal', 'oracle_count']]\n",
    "\n",
    "    return df_an1, df_an2\n",
    "\n",
    "def pretty_print_latex(latex_str):\n",
    "    lines = latex_str.replace(r\" \\\\ \", r\" \\\\\" + \"\\n\").splitlines()\n",
    "    formatted_lines = []\n",
    "    indent_level = 0\n",
    "    for line in lines:\n",
    "        if r\"\\begin\" in line:\n",
    "            formatted_lines.append(line)\n",
    "            indent_level += 1\n",
    "        elif r\"\\end\" in line:\n",
    "            indent_level -= 1\n",
    "            formatted_lines.append(line)\n",
    "        else:\n",
    "            formatted_lines.append(\"    \" * indent_level + line)\n",
    "    return \"\\n\".join(formatted_lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f171857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Generator</th>\n",
       "            <th>Kappa Sentiment</th>\n",
       "            <th>Kappa Title</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Llama-3.3-70B</td>\n",
       "            <td>0.84</td>\n",
       "            <td>-0.01</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Llama-2-7B</td>\n",
       "            <td>0.72</td>\n",
       "            <td>-0.02</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Mistral-7B</td>\n",
       "            <td>0.72</td>\n",
       "            <td>0.17</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Avg</td>\n",
       "            <td>0.76</td>\n",
       "            <td>0.05</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------+-----------------+-------------+\n",
       "|   Generator   | Kappa Sentiment | Kappa Title |\n",
       "+---------------+-----------------+-------------+\n",
       "| Llama-3.3-70B |       0.84      |    -0.01    |\n",
       "|   Llama-2-7B  |       0.72      |    -0.02    |\n",
       "|   Mistral-7B  |       0.72      |     0.17    |\n",
       "|      Avg      |       0.76      |     0.05    |\n",
       "+---------------+-----------------+-------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = PrettyTable(['Generator', 'Kappa Sentiment', 'Kappa Title'])\n",
    "\n",
    "kappa_sum = 0\n",
    "kappa_title_sum = 0\n",
    "for id, path in MODEL.items():\n",
    "    df_an1, df_an2 = get_oracle_ratings_per_annotator(path)\n",
    "    kappa = cohen_kappa_score(df_an1['oracle'], df_an2['oracle'])\n",
    "    kappa_title = cohen_kappa_score(df_an1['oracle_title_match'], df_an2['oracle_title_match'])\n",
    "\n",
    "    kappa_sum += kappa\n",
    "    kappa_title_sum += kappa_title\n",
    "    \n",
    "    t.add_row([id, round(kappa, 2), round(kappa_title, 2)])\n",
    "\n",
    "\n",
    "t.add_row(['Avg', round(kappa_sum/len(MODEL), 2), round(kappa_title_sum/len(MODEL), 2)])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f6b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ccc}\n",
      "    Generator & Kappa Sentiment & Kappa Title \\\\\n",
      "    Llama-3.3-70B & 0.84 & -0.01 \\\\\n",
      "    Llama-2-7B & 0.72 & -0.02 \\\\\n",
      "    Mistral-7B & 0.72 & 0.17 \\\\\n",
      "    Avg & 0.76 & 0.05 \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "l = pretty_print_latex(t.get_latex_string())\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833850f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/MSE/03_projects/VT2/02_code/01_evaluation-toolkit/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Users/felix/MSE/03_projects/VT2/02_code/01_evaluation-toolkit/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/Users/felix/MSE/03_projects/VT2/02_code/01_evaluation-toolkit/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "/Users/felix/MSE/03_projects/VT2/02_code/01_evaluation-toolkit/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:758: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Generator</th>\n",
       "            <th>Kappa Animal Type</th>\n",
       "            <th>Kappa Animal Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Stable Diffusion 3.5</td>\n",
       "            <td>1.0</td>\n",
       "            <td>0.71</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Stable Cascade</td>\n",
       "            <td>0.83</td>\n",
       "            <td>0.79</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>FLUX.1-dev</td>\n",
       "            <td>1.0</td>\n",
       "            <td>0.98</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Avg</td>\n",
       "            <td>0.94</td>\n",
       "            <td>0.82</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------+-------------------+--------------------+\n",
       "|      Generator       | Kappa Animal Type | Kappa Animal Count |\n",
       "+----------------------+-------------------+--------------------+\n",
       "| Stable Diffusion 3.5 |        1.0        |        0.71        |\n",
       "|    Stable Cascade    |        0.83       |        0.79        |\n",
       "|      FLUX.1-dev      |        1.0        |        0.98        |\n",
       "|         Avg          |        0.94       |        0.82        |\n",
       "+----------------------+-------------------+--------------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = PrettyTable(['Generator', 'Kappa Animal Type', 'Kappa Animal Count'])\n",
    "\n",
    "kappa_sum = 0\n",
    "kappa_title_sum = 0\n",
    "for id, path in IMAGE_MODEL.items():\n",
    "    df_an1, df_an2 = get_oracle_ratings_per_annotator_image(path)\n",
    "    kappa = cohen_kappa_score(df_an1['oracle_animal'], df_an2['oracle_animal'])\n",
    "    kappa_title = cohen_kappa_score(df_an1['oracle_count'], df_an2['oracle_count'])\n",
    "\n",
    "    kappa = np.nan_to_num(kappa, nan=1)\n",
    "\n",
    "    kappa_sum += kappa\n",
    "    kappa_title_sum += kappa_title\n",
    "    \n",
    "    t.add_row([id, round(kappa, 2), round(kappa_title, 2)])\n",
    "\n",
    "\n",
    "t.add_row(['Avg', round(kappa_sum/len(MODEL), 2), round(kappa_title_sum/len(MODEL), 2)])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36889b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ccc}\n",
      "    Generator & Kappa Animal Type & Kappa Animal Count \\\\\n",
      "    Stable Diffusion 3.5 & 1.0 & 0.71 \\\\\n",
      "    Stable Cascade & 0.83 & 0.79 \\\\\n",
      "    FLUX.1-dev & 1.0 & 0.98 \\\\\n",
      "    Avg & 0.94 & 0.82 \\\\\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "l = pretty_print_latex(t.get_latex_string())\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
